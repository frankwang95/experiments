{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from learning_lib.nn.monitoring.loss import LossMonitor\n",
    "from learning_lib.nn.ffnn import FFNN\n",
    "from learning_lib.nn.cnn import CNN\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import plotly.offline as plotly\n",
    "import plotly.graph_objs as go\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plotly.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare convolutional neural networks against the feed-forwards variety on MNIST with the aim of improving test accuracy and reduce the number of trainable parameters. We then inspect the filters / convoluted images to see if the \"learned features\" are human interprable in any way.\n",
    "\n",
    "Furthermore we show that it is a easier task to learn pattersn from the learned convolutional feature representation of images than it is to classify the raw images itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gzip.open('MNIST_data/test_input.gz', 'rb') as f:\n",
    "    test_in = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28) / 255.0\n",
    "with gzip.open('MNIST_data/train_input.gz', 'rb') as f:\n",
    "    train_in = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28) / 255.0\n",
    "with gzip.open('MNIST_data/test_targets.gz', 'rb') as f:\n",
    "    test_labels_raw = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "with gzip.open('MNIST_data/train_targets.gz', 'rb') as f:\n",
    "    train_labels_raw = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    \n",
    "test_labels = np.zeros((test_labels_raw.shape[0], 10))\n",
    "test_labels[np.arange(test_labels_raw.shape[0]), test_labels_raw] = 1\n",
    "train_labels = np.zeros((train_labels_raw.shape[0], 10))\n",
    "train_labels[np.arange(train_labels_raw.shape[0]), train_labels_raw] = 1\n",
    "\n",
    "test_in = test_in.astype('float32')\n",
    "train_in = train_in.astype('float32')\n",
    "test_lables = test_labels.astype('float32')\n",
    "train_lables = train_labels.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run this if you want to normalize to zero mean\n",
    "test_in = test_in - train_in.mean()\n",
    "train_in = train_in - train_in.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feed Forwards Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we see that four hidden layers with 128 nodes each achieves 97.88% testing accuracy. Our goal is therefore to beat this number using at most this many parameters.\n",
    "\n",
    "Tally of number of parameters:\n",
    "- layer 1: 784 * 128 + 128 = 100480\n",
    "- layer 2: 128 * 128 + 128 = 16512\n",
    "- layer 3: 128 * 128 + 128 = 16512\n",
    "- layer 4: 128 * 128 + 128 = 16512\n",
    "- layer 5: 128 * 10 + 10 = 1290\n",
    "- total: 100480 + 16512 + 16512 + 16512 + 1290 = 151306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = tf.data.Dataset.from_tensor_slices((train_in, train_labels))\n",
    "d = d.repeat(50)\n",
    "d = d.batch(300)\n",
    "iterator = d.make_initializable_iterator()\n",
    "pipe_out = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lc = [\n",
    "    784,\n",
    "    {\n",
    "        'n_nodes': 128, 'activation': tf.tanh, 'init_weight_mean': 0.0, 'init_weight_stddev': 0.01,\n",
    "        'init_bias_mean': 0.0, 'init_bias_stddev': 0.01\n",
    "    },\n",
    "    {\n",
    "        'n_nodes': 128, 'activation': tf.tanh, 'init_weight_mean': 0.0, 'init_weight_stddev': 0.01,\n",
    "        'init_bias_mean': 0.0, 'init_bias_stddev': 0.01\n",
    "    },\n",
    "    {\n",
    "        'n_nodes': 128, 'activation': tf.tanh, 'init_weight_mean': 0.0, 'init_weight_stddev': 0.01,\n",
    "        'init_bias_mean': 0.0, 'init_bias_stddev': 0.01\n",
    "    },\n",
    "    {\n",
    "        'n_nodes': 128, 'activation': tf.tanh, 'init_weight_mean': 0.0, 'init_weight_stddev': 0.01,\n",
    "        'init_bias_mean': 0.0, 'init_bias_stddev': 0.01\n",
    "    },\n",
    "    {\n",
    "        'n_nodes': 10, 'activation': tf.tanh, 'init_weight_mean': 0.0, 'init_weight_stddev': 0.01,\n",
    "        'init_bias_mean': 0.0, 'init_bias_stddev': 0.01\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_with_softmax(model_output, true_output):\n",
    "    return tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(labels=true_output, logits=model_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "monitors = [LossMonitor(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ffnn = FFNN(\n",
    "    lc, monitors=monitors, optimizer=tf.train.AdamOptimizer(), input_vector=pipe_out[0], train_targets_vector=pipe_out[1]\n",
    ")\n",
    "ffnn.init_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 4.08 s, total: 1min 17s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1):\n",
    "    ffnn.session.run(iterator.initializer)\n",
    "    ffnn.train_online()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plotly.iplot(ffnn.monitors[0].plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992363636363636"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = ffnn.predict(train_in)\n",
    "np.sum(train_pred.argmax(axis=1) == train_labels.argmax(axis=1)) / train_in.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = ffnn.predict(test_in)\n",
    "np.sum(train_pred.argmax(axis=1) == test_labels.argmax(axis=1)) / test_in.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Convolutional Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We achieve significantly better performance (between 98.35% and 98.55%) with only 8648 trainable parameters.\n",
    "\n",
    "Tally of number of parameters:\n",
    "- layer 1: 5 \\* 5 * 8 = 200\n",
    "- layer 2: 5 \\* 5 \\* 8 * 8 = 1600\n",
    "- layer 3: 5 \\* 5 \\* 8 * 8 = 1600\n",
    "- layer 4: 72 * 64 = 4608\n",
    "- layer 5: 64 * 10 = 640\n",
    "- total: 200 + 1600 + 1600 + 4608 + 640 = 8648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = tf.data.Dataset.from_tensor_slices((train_in.reshape((110000, 28, 28, 1)), train_labels))\n",
    "d = d.repeat(50)\n",
    "d = d.batch(300)\n",
    "iterator = d.make_initializable_iterator()\n",
    "pipe_out = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lc = [\n",
    "    {\n",
    "        'layer_type': 'conv',\n",
    "        'filter_size': [5, 5, 1, 8],\n",
    "        'init_filter_mean': 0.0,\n",
    "        'init_filter_stddev': 0.001,\n",
    "        'stride_size': [1, 1, 1, 1],\n",
    "        'activation': tf.tanh\n",
    "    },\n",
    "    {\n",
    "        'layer_type': 'conv',\n",
    "        'filter_size': [5, 5, 8, 8],\n",
    "        'init_filter_mean': 0.0,\n",
    "        'init_filter_stddev': 0.001,\n",
    "        'stride_size': [1, 3, 3, 1],\n",
    "        'activation': tf.tanh\n",
    "    },\n",
    "    {\n",
    "        'layer_type': 'conv',\n",
    "        'filter_size': [5, 5, 8, 8],\n",
    "        'init_filter_mean': 0.0,\n",
    "        'init_filter_stddev': 0.001,\n",
    "        'stride_size': [1, 1, 1, 1],\n",
    "        'activation': tf.tanh\n",
    "    },\n",
    "    {\n",
    "        'layer_type': 'reshape',\n",
    "        'new_shape': [72]\n",
    "    },\n",
    "    {\n",
    "        'layer_type': 'connected',\n",
    "        'input_dim': 72,\n",
    "        'output_dim': 64,\n",
    "        'activation': tf.tanh,\n",
    "        'init_weight_mean': 0.0,\n",
    "        'init_weight_stddev': 0.001,\n",
    "        'init_bias_mean': 0.0,\n",
    "        'init_bias_stddev': 0.001\n",
    "    },\n",
    "    {\n",
    "        'layer_type': 'connected',\n",
    "        'input_dim': 64,\n",
    "        'output_dim': 10,\n",
    "        'activation': tf.tanh,\n",
    "        'init_weight_mean': 0.0,\n",
    "        'init_weight_stddev': 0.001,\n",
    "        'init_bias_mean': 0.0,\n",
    "        'init_bias_stddev': 0.001\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "monitors = [LossMonitor(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cnn = CNN(\n",
    "    lc, monitors=monitors, optimizer=tf.train.AdamOptimizer(), input_vector=pipe_out[0], train_targets_vector=pipe_out[1]\n",
    ")\n",
    "cnn.init_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 57s, sys: 28.6 s, total: 7min 26s\n",
      "Wall time: 6min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(5):\n",
    "    cnn.session.run(iterator.initializer)\n",
    "    cnn.train_online()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "scatter",
         "x": [
          0,
          200,
          400,
          600,
          800,
          1000,
          1200,
          1400,
          1600,
          1800,
          2000,
          2200,
          2400,
          2600,
          2800,
          3000,
          3200,
          3400,
          3600,
          3800,
          4000,
          4200,
          4400,
          4600,
          4800,
          5000,
          5200,
          5400,
          5600,
          5800,
          6000,
          6200,
          6400,
          6600,
          6800,
          7000,
          7200,
          7400,
          7600,
          7800,
          8000,
          8200,
          8400,
          8600,
          8800,
          9000,
          9200,
          9400,
          9600,
          9800,
          10000,
          10200,
          10400,
          10600,
          10800,
          11000,
          11200,
          11400,
          11600,
          11800,
          12000,
          12200,
          12400,
          12600,
          12800,
          13000,
          13200,
          13400,
          13600,
          13800,
          14000,
          14200,
          14400,
          14600,
          14800,
          15000,
          15200,
          15400,
          15600,
          15800,
          16000,
          16200,
          16400,
          16600,
          16800,
          17000,
          17200,
          17400,
          17600,
          17800,
          18000,
          18200,
          18400,
          18600,
          18800,
          19000,
          19200,
          19400,
          19600,
          19800,
          20000,
          20200,
          20400,
          20600,
          20800,
          21000,
          21200,
          21400,
          21600,
          21800,
          22000,
          22200,
          22400,
          22600,
          22800,
          23000,
          23200,
          23400,
          23600,
          23800,
          24000,
          24200,
          24400,
          24600,
          24800,
          25000,
          25200,
          25400,
          25600,
          25800,
          26000,
          26200,
          26400,
          26600,
          26800,
          27000,
          27200,
          27400,
          27600,
          27800,
          28000,
          28200,
          28400,
          28600,
          28800,
          29000,
          29200,
          29400,
          29600,
          29800,
          30000,
          30200,
          30400,
          30600,
          30800,
          31000,
          31200,
          31400,
          31600,
          31800,
          32000,
          32200,
          32400,
          32600,
          32800,
          33000,
          33200,
          33400,
          33600,
          33800,
          34000,
          34200,
          34400,
          34600,
          34800,
          35000,
          35200,
          35400,
          35600,
          35800,
          36000,
          36200,
          36400,
          36600,
          36800,
          37000,
          37200,
          37400,
          37600,
          37800,
          38000,
          38200,
          38400,
          38600,
          38800,
          39000,
          39200,
          39400,
          39600,
          39800,
          40000,
          40200,
          40400,
          40600,
          40800,
          41000,
          41200,
          41400,
          41600,
          41800,
          42000,
          42200,
          42400,
          42600,
          42800,
          43000,
          43200,
          43400,
          43600,
          43800,
          44000,
          44200,
          44400,
          44600,
          44800,
          45000,
          45200,
          45400,
          45600,
          45800,
          46000,
          46200,
          46400,
          46600,
          46800,
          47000,
          47200,
          47400,
          47600,
          47800,
          48000,
          48200,
          48400,
          48600,
          48800,
          49000,
          49200,
          49400,
          49600,
          49800,
          50000,
          50200,
          50400,
          50600,
          50800,
          51000,
          51200,
          51400,
          51600,
          51800,
          52000,
          52200,
          52400,
          52600,
          52800,
          53000,
          53200,
          53400,
          53600,
          53800,
          54000,
          54200,
          54400,
          54600,
          54800,
          55000,
          55200,
          55400,
          55600,
          55800,
          56000,
          56200,
          56400,
          56600,
          56800,
          57000,
          57200,
          57400,
          57600,
          57800,
          58000,
          58200,
          58400,
          58600,
          58800,
          59000,
          59200,
          59400,
          59600,
          59800,
          60000,
          60200,
          60400,
          60600,
          60800,
          61000,
          61200,
          61400,
          61600,
          61800,
          62000,
          62200,
          62400,
          62600,
          62800,
          63000,
          63200,
          63400,
          63600,
          63800,
          64000,
          64200,
          64400,
          64600,
          64800,
          65000,
          65200,
          65400,
          65600,
          65800,
          66000,
          66200,
          66400,
          66600,
          66800,
          67000,
          67200,
          67400,
          67600,
          67800,
          68000,
          68200,
          68400,
          68600,
          68800,
          69000,
          69200,
          69400,
          69600,
          69800,
          70000,
          70200,
          70400,
          70600,
          70800,
          71000,
          71200,
          71400,
          71600,
          71800,
          72000,
          72200,
          72400,
          72600,
          72800,
          73000,
          73200,
          73400,
          73600,
          73800,
          74000,
          74200,
          74400,
          74600,
          74800,
          75000,
          75200,
          75400,
          75600,
          75800,
          76000,
          76200,
          76400,
          76600,
          76800,
          77000,
          77200,
          77400,
          77600,
          77800,
          78000,
          78200,
          78400,
          78600,
          78800,
          79000,
          79200,
          79400,
          79600,
          79800,
          80000,
          80200,
          80400,
          80600,
          80800,
          81000,
          81200,
          81400,
          81600,
          81800,
          82000,
          82200,
          82400,
          82600,
          82800,
          83000,
          83200,
          83400,
          83600,
          83800,
          84000,
          84200,
          84400,
          84600,
          84800,
          85000,
          85200,
          85400,
          85600,
          85800,
          86000,
          86200,
          86400,
          86600,
          86800,
          87000,
          87200,
          87400,
          87600,
          87800,
          88000,
          88200,
          88400,
          88600,
          88800,
          89000,
          89200,
          89400,
          89600,
          89800,
          90000,
          90200,
          90400,
          90600,
          90800,
          91000,
          91200
         ],
         "y": [
          0.09982825815677643,
          0.08992502838373184,
          0.03833387792110443,
          0.019846154376864433,
          0.014690927229821682,
          0.012804585509002209,
          0.009597797878086567,
          0.00897055771201849,
          0.006471734493970871,
          0.008355860598385334,
          0.005969693418592215,
          0.004501638934016228,
          0.005738754291087389,
          0.004545500036329031,
          0.005133424885571003,
          0.007848013192415237,
          0.005817303899675608,
          0.0038887509144842625,
          0.005380994640290737,
          0.003365126671269536,
          0.003884510602802038,
          0.002982339821755886,
          0.0039657908491790295,
          0.0038417892064899206,
          0.004687155596911907,
          0.005711769685149193,
          0.004514370113611221,
          0.002508781151846051,
          0.003322915406897664,
          0.005034629721194506,
          0.003608274506404996,
          0.003282000310719013,
          0.0032325529027730227,
          0.0028356672264635563,
          0.002343150321394205,
          0.003259610151872039,
          0.003838069038465619,
          0.004047464579343796,
          0.002793861785903573,
          0.0033053632359951735,
          0.002785539021715522,
          0.002351125469431281,
          0.0011018523946404457,
          0.003327626269310713,
          0.0014367743860930204,
          0.0024256964679807425,
          0.00263962778262794,
          0.0026536881923675537,
          0.002448467770591378,
          0.0020995216909796,
          0.002224134048447013,
          0.0035898122005164623,
          0.002662225626409054,
          0.003382493741810322,
          0.0036875256337225437,
          0.0012970154639333487,
          0.0025756412651389837,
          0.0023525976575911045,
          0.003074686275795102,
          0.003983930218964815,
          0.0028668344020843506,
          0.0014079547254368663,
          0.0020989933982491493,
          0.0009791876655071974,
          0.0027901558205485344,
          0.0015891542425379157,
          0.0018014045199379325,
          0.0017058310331776738,
          0.0028710155747830868,
          0.0016030650585889816,
          0.0009073832770809531,
          0.001302790711633861,
          0.0015826411545276642,
          0.0025531412102282047,
          0.001993748592212796,
          0.0013122993987053633,
          0.0009347574668936431,
          0.0015473348321393132,
          0.0018171811243519187,
          0.0028685436118394136,
          0.0015798945678398013,
          0.0007525735418312252,
          0.0012130595277994871,
          0.0012907532509416342,
          0.0012718327343463898,
          0.0017461233073845506,
          0.0019364882027730346,
          0.0011295771691948175,
          0.0010143147082999349,
          0.0029381471686065197,
          0.0035931116435676813,
          0.00081012980081141,
          0.0017568552866578102,
          0.0008182203164324164,
          0.002232236322015524,
          0.0004904409288428724,
          0.002640628255903721,
          0.0006130975671112537,
          0.0012349880998954177,
          0.0017470002640038729,
          0.0016588115831837058,
          0.0017698227893561125,
          0.0008224096382036805,
          0.0014911529142409563,
          0.001700543682090938,
          0.0020264398772269487,
          0.0013217083178460598,
          0.0018333770567551255,
          0.001484185690060258,
          0.0017677188152447343,
          0.0018302793614566326,
          0.0017767890822142363,
          0.0008182362071238458,
          0.0014440699014812708,
          0.0021909999195486307,
          0.0014221521560102701,
          0.0012596866581588984,
          0.0019383151084184647,
          0.0018782838014885783,
          0.0008897940278984606,
          0.0010535467881709337,
          0.0013942262157797813,
          0.001768046640790999,
          0.0010537953348830342,
          0.00128702144138515,
          0.001180575811304152,
          0.003010484389960766,
          0.0025537440087646246,
          0.002245714422315359,
          0.0009801086271181703,
          0.0013102232478559017,
          0.0007812926196493208,
          0.0009798785904422402,
          0.001425801427103579,
          0.0010011059930548072,
          0.0013287157053127885,
          0.0013019638136029243,
          0.0022151803132146597,
          0.0008646181668154895,
          0.000769111153203994,
          0.0026224174071103334,
          0.0006148067186586559,
          0.0009587909444235265,
          0.00121422263327986,
          0.0003932006366085261,
          0.0012115852441638708,
          0.0005931909545324743,
          0.0005572829395532608,
          0.0009270255686715245,
          0.0003833514347206801,
          0.0009527528891339898,
          0.0005170574295334518,
          0.0009012797963805497,
          0.0023774360306560993,
          0.0017641077283769846,
          0.0009831479983404279,
          0.0021358097437769175,
          0.0010837387526407838,
          0.0010734094539657235,
          0.0012807641178369522,
          0.001099580549634993,
          0.0013626489089801908,
          0.0006419931887649,
          0.0008760448545217514,
          0.0008043097914196551,
          0.0006054864497855306,
          0.001095202169381082,
          0.0019819748122245073,
          0.0003823263687081635,
          0.0009948930237442255,
          0.00040904045454226434,
          0.0019707242026925087,
          0.0010846969671547413,
          0.0005969310877844691,
          0.0005859819939360023,
          0.0005787317641079426,
          0.0009669594583101571,
          0.001123539637774229,
          0.0013899228069931269,
          0.0009360566036775708,
          0.00095338374376297,
          0.0009056426933966577,
          0.0019501809729263186,
          0.0008881118264980614,
          0.0008021827670745552,
          0.0009448446216993034,
          0.0009098314330913126,
          0.0009853715309873223,
          0.0009003370068967342,
          0.0013660427648574114,
          0.00030933591187931597,
          0.001042822957970202,
          0.0010705071035772562,
          0.0006330822361633182,
          0.000686360988765955,
          0.0011997349793091416,
          0.00042055503581650555,
          0.0008003134862519801,
          0.000638218189124018,
          0.000720321957487613,
          0.0007456092862412333,
          0.0007241753628477454,
          0.0006137548480182886,
          0.0007949175196699798,
          0.0005866067367605865,
          0.0002681682235561311,
          0.0006623548688367009,
          0.0008493222412653267,
          0.0014163402374833822,
          0.0005795859615318477,
          0.0010272663785144687,
          0.00035547875449992716,
          0.0010011795675382018,
          0.0006844616727903485,
          0.001340547576546669,
          0.0013233822537586093,
          0.0003961938200518489,
          0.0011098047252744436,
          0.0010969866998493671,
          0.0017964838771149516,
          0.00047168415039777756,
          0.0010170878376811743,
          0.00034984329249709845,
          0.0007064510718919337,
          0.0017732195556163788,
          0.001266288454644382,
          0.0010568209690973163,
          0.000511987367644906,
          0.0021075971890240908,
          0.0017183867748826742,
          0.0010817982256412506,
          0.0006556865409947932,
          0.0008776644244790077,
          0.0005250608664937317,
          0.000404463178711012,
          0.0004871460550930351,
          0.000350016460288316,
          0.000805498450063169,
          0.0008309207623824477,
          0.0017273792764171958,
          0.001048704027198255,
          0.0002129222557414323,
          0.0015122521435841918,
          0.0010178283555433154,
          0.000527719035744667,
          0.0013625748688355088,
          0.00030603448976762593,
          0.0006039010477252305,
          0.00035679570282809436,
          0.0016787286149337888,
          0.0013231165939942002,
          0.0003124876820947975,
          0.0008437117794528604,
          0.001033079344779253,
          0.0014791692374274135,
          0.000267607974819839,
          0.0005424085538834333,
          0.0008583485032431781,
          0.00038442149525508285,
          0.0006411589565686882,
          0.0008517670794390142,
          0.0010012493003159761,
          0.001036929665133357,
          0.00023398635676130652,
          0.0011176461121067405,
          0.0001837071613408625,
          0.0002715095761232078,
          0.0008789515704847872,
          0.0005100186099298298,
          0.0007000561454333365,
          0.0008711919072084129,
          0.00043502484913915396,
          0.000354730524122715,
          0.0007161293760873377,
          0.00029012328013777733,
          0.001384928124025464,
          0.00016534152382519096,
          0.000967650965321809,
          0.0013266532914713025,
          0.0003916605201084167,
          0.0007726634503342211,
          0.0005063456483185291,
          0.0009657324990257621,
          0.00042394702904857695,
          0.0002147962077287957,
          0.0008941460982896388,
          0.00020261984900571406,
          0.0003341849660500884,
          0.001354689011350274,
          0.001569501357153058,
          0.0003551356785465032,
          0.0011179129360243678,
          0.0008422164828516543,
          0.0004565351700875908,
          0.0010076864855363965,
          0.0010883761569857597,
          0.0006259334040805697,
          0.0008488188032060862,
          0.0003771606716327369,
          0.0004942197119817138,
          0.0002940972335636616,
          0.0005191115778870881,
          0.0010448571993038058,
          0.0003414173552300781,
          0.0007909860578365624,
          0.000840348657220602,
          0.0005116944084875286,
          0.0008500748663209379,
          0.0003594367590267211,
          0.000479974813060835,
          0.0007206284790299833,
          0.0005032623885199428,
          0.0009809356415644288,
          0.0007995071937330067,
          0.0011895281495526433,
          0.0004544459516182542,
          0.00027385889552533627,
          0.0006523439660668373,
          0.0003942220937460661,
          0.0009211997385136783,
          0.0003075633430853486,
          0.0007370958337560296,
          0.0011017433134838939,
          0.00037646721466444433,
          0.0011339850025251508,
          0.0013143495889380574,
          0.0014623472234234214,
          0.0009329527383670211,
          0.0014442414976656437,
          0.0008898079977370799,
          0.0005020669777877629,
          0.0014202800812199712,
          0.0022234225180000067,
          0.001596585614606738,
          0.00032724521588534117,
          0.0007834550342522562,
          0.00013204132847022265,
          0.0008186075720004737,
          0.00026182629517279565,
          0.00028603558894246817,
          0.001938491826876998,
          0.0010086871916428208,
          0.0006616893806494772,
          0.0004933649906888604,
          0.00028608072898350656,
          0.0006512743420898914,
          0.0005651499959640205,
          0.0006584650836884975,
          0.000595666526351124,
          0.00020961358677595854,
          0.0008987976470962167,
          0.00048192794201895595,
          0.00031503886566497386,
          0.0005924026481807232,
          0.00033207586966454983,
          0.0005130236968398094,
          0.00024785238201729953,
          0.000543446047231555,
          0.0006044250912964344,
          0.0009226577240042388,
          0.0007645290461368859,
          0.0005501311388798058,
          0.0008333532023243606,
          0.000804304436314851,
          0.0005774781457148492,
          0.001005694386549294,
          0.00043416611151769757,
          0.0002168744831578806,
          0.00028917379677295685,
          0.00021790126629639417,
          0.00024792581098154187,
          0.0003734096826519817,
          0.0003140481421723962,
          0.0002440188982291147,
          0.001883504563011229,
          0.0007135228952392936,
          0.0006246534758247435,
          0.0011099668918177485,
          0.0006187111139297485,
          0.00014589063357561827,
          0.0010522996308282018,
          0.0003064074262510985,
          0.00018801327678374946,
          0.00018569594249129295,
          0.000512988306581974,
          0.0015535133425146341,
          0.0004120526718907058,
          0.00037665513809770346,
          0.0013763847528025508,
          0.0015507431235164404,
          0.0003722166293300688,
          0.0004251455538906157,
          0.0006939004524610937,
          0.0004083884123247117,
          0.00020204314205329865,
          0.0004574054037220776,
          0.0009591639973223209,
          0.00030773223261348903,
          0.0004668283509090543,
          0.0006481885793618858,
          0.00011720089241862297,
          0.00023329895338974893,
          0.00018487262423150241,
          0.00047996893408708274,
          0.0010425143409520388,
          0.0008425042033195496,
          0.000461757619632408,
          0.0001504814572399482,
          0.00046332221245393157,
          0.0002981995639856905,
          0.00043796043610200286,
          0.0005487558082677424,
          0.00035661656875163317,
          0.00014591685612685978,
          0.0010125681292265654,
          0.0002606864436529577,
          0.00035916976048611104,
          0.00036607691436074674,
          0.0006782840355299413,
          0.00048415048513561487,
          0.00024752403260208666,
          0.0006531815743073821,
          0.0005018160445615649,
          0.00014604245370719582,
          0.0010976288467645645,
          0.0003817034885287285,
          0.0006445100880227983,
          0.0008858448709361255,
          0.0006809182814322412,
          0.001000251155346632,
          0.0002250353863928467,
          0.00027052941732108593,
          0.0013490088749676943,
          0.0009020438883453608,
          0.0002971063950099051,
          0.0001708257623249665,
          0.00018380778783466667,
          0.0005502503481693566,
          0.0009314780472777784,
          0.0003072369145229459,
          0.0005381049122661352,
          0.0009282746468670666,
          0.0006999557954259217,
          0.0011442000977694988,
          0.0007208707393147051,
          0.0011853550095111132,
          0.00030075671384111047,
          0.00012627712567336857,
          0.0005602711462415755,
          0.00018954901315737516,
          0.0007175737409852445,
          0.0006842142902314663,
          0.001582951983436942,
          0.00030367716681212187,
          0.0002816766791511327,
          0.0002035229845205322,
          0.0004748672363348305
         ]
        }
       ],
       "layout": {
        "title": "Model Loss vs. Epochs",
        "xaxis": {
         "title": "Epochs"
        },
        "yaxis": {
         "title": "Loss"
        }
       }
      },
      "text/html": [
       "<div id=\"a7a2224e-19b1-4deb-96d3-3768a0460b04\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"a7a2224e-19b1-4deb-96d3-3768a0460b04\", [{\"type\": \"scatter\", \"x\": [0.0, 200.0, 400.0, 600.0, 800.0, 1000.0, 1200.0, 1400.0, 1600.0, 1800.0, 2000.0, 2200.0, 2400.0, 2600.0, 2800.0, 3000.0, 3200.0, 3400.0, 3600.0, 3800.0, 4000.0, 4200.0, 4400.0, 4600.0, 4800.0, 5000.0, 5200.0, 5400.0, 5600.0, 5800.0, 6000.0, 6200.0, 6400.0, 6600.0, 6800.0, 7000.0, 7200.0, 7400.0, 7600.0, 7800.0, 8000.0, 8200.0, 8400.0, 8600.0, 8800.0, 9000.0, 9200.0, 9400.0, 9600.0, 9800.0, 10000.0, 10200.0, 10400.0, 10600.0, 10800.0, 11000.0, 11200.0, 11400.0, 11600.0, 11800.0, 12000.0, 12200.0, 12400.0, 12600.0, 12800.0, 13000.0, 13200.0, 13400.0, 13600.0, 13800.0, 14000.0, 14200.0, 14400.0, 14600.0, 14800.0, 15000.0, 15200.0, 15400.0, 15600.0, 15800.0, 16000.0, 16200.0, 16400.0, 16600.0, 16800.0, 17000.0, 17200.0, 17400.0, 17600.0, 17800.0, 18000.0, 18200.0, 18400.0, 18600.0, 18800.0, 19000.0, 19200.0, 19400.0, 19600.0, 19800.0, 20000.0, 20200.0, 20400.0, 20600.0, 20800.0, 21000.0, 21200.0, 21400.0, 21600.0, 21800.0, 22000.0, 22200.0, 22400.0, 22600.0, 22800.0, 23000.0, 23200.0, 23400.0, 23600.0, 23800.0, 24000.0, 24200.0, 24400.0, 24600.0, 24800.0, 25000.0, 25200.0, 25400.0, 25600.0, 25800.0, 26000.0, 26200.0, 26400.0, 26600.0, 26800.0, 27000.0, 27200.0, 27400.0, 27600.0, 27800.0, 28000.0, 28200.0, 28400.0, 28600.0, 28800.0, 29000.0, 29200.0, 29400.0, 29600.0, 29800.0, 30000.0, 30200.0, 30400.0, 30600.0, 30800.0, 31000.0, 31200.0, 31400.0, 31600.0, 31800.0, 32000.0, 32200.0, 32400.0, 32600.0, 32800.0, 33000.0, 33200.0, 33400.0, 33600.0, 33800.0, 34000.0, 34200.0, 34400.0, 34600.0, 34800.0, 35000.0, 35200.0, 35400.0, 35600.0, 35800.0, 36000.0, 36200.0, 36400.0, 36600.0, 36800.0, 37000.0, 37200.0, 37400.0, 37600.0, 37800.0, 38000.0, 38200.0, 38400.0, 38600.0, 38800.0, 39000.0, 39200.0, 39400.0, 39600.0, 39800.0, 40000.0, 40200.0, 40400.0, 40600.0, 40800.0, 41000.0, 41200.0, 41400.0, 41600.0, 41800.0, 42000.0, 42200.0, 42400.0, 42600.0, 42800.0, 43000.0, 43200.0, 43400.0, 43600.0, 43800.0, 44000.0, 44200.0, 44400.0, 44600.0, 44800.0, 45000.0, 45200.0, 45400.0, 45600.0, 45800.0, 46000.0, 46200.0, 46400.0, 46600.0, 46800.0, 47000.0, 47200.0, 47400.0, 47600.0, 47800.0, 48000.0, 48200.0, 48400.0, 48600.0, 48800.0, 49000.0, 49200.0, 49400.0, 49600.0, 49800.0, 50000.0, 50200.0, 50400.0, 50600.0, 50800.0, 51000.0, 51200.0, 51400.0, 51600.0, 51800.0, 52000.0, 52200.0, 52400.0, 52600.0, 52800.0, 53000.0, 53200.0, 53400.0, 53600.0, 53800.0, 54000.0, 54200.0, 54400.0, 54600.0, 54800.0, 55000.0, 55200.0, 55400.0, 55600.0, 55800.0, 56000.0, 56200.0, 56400.0, 56600.0, 56800.0, 57000.0, 57200.0, 57400.0, 57600.0, 57800.0, 58000.0, 58200.0, 58400.0, 58600.0, 58800.0, 59000.0, 59200.0, 59400.0, 59600.0, 59800.0, 60000.0, 60200.0, 60400.0, 60600.0, 60800.0, 61000.0, 61200.0, 61400.0, 61600.0, 61800.0, 62000.0, 62200.0, 62400.0, 62600.0, 62800.0, 63000.0, 63200.0, 63400.0, 63600.0, 63800.0, 64000.0, 64200.0, 64400.0, 64600.0, 64800.0, 65000.0, 65200.0, 65400.0, 65600.0, 65800.0, 66000.0, 66200.0, 66400.0, 66600.0, 66800.0, 67000.0, 67200.0, 67400.0, 67600.0, 67800.0, 68000.0, 68200.0, 68400.0, 68600.0, 68800.0, 69000.0, 69200.0, 69400.0, 69600.0, 69800.0, 70000.0, 70200.0, 70400.0, 70600.0, 70800.0, 71000.0, 71200.0, 71400.0, 71600.0, 71800.0, 72000.0, 72200.0, 72400.0, 72600.0, 72800.0, 73000.0, 73200.0, 73400.0, 73600.0, 73800.0, 74000.0, 74200.0, 74400.0, 74600.0, 74800.0, 75000.0, 75200.0, 75400.0, 75600.0, 75800.0, 76000.0, 76200.0, 76400.0, 76600.0, 76800.0, 77000.0, 77200.0, 77400.0, 77600.0, 77800.0, 78000.0, 78200.0, 78400.0, 78600.0, 78800.0, 79000.0, 79200.0, 79400.0, 79600.0, 79800.0, 80000.0, 80200.0, 80400.0, 80600.0, 80800.0, 81000.0, 81200.0, 81400.0, 81600.0, 81800.0, 82000.0, 82200.0, 82400.0, 82600.0, 82800.0, 83000.0, 83200.0, 83400.0, 83600.0, 83800.0, 84000.0, 84200.0, 84400.0, 84600.0, 84800.0, 85000.0, 85200.0, 85400.0, 85600.0, 85800.0, 86000.0, 86200.0, 86400.0, 86600.0, 86800.0, 87000.0, 87200.0, 87400.0, 87600.0, 87800.0, 88000.0, 88200.0, 88400.0, 88600.0, 88800.0, 89000.0, 89200.0, 89400.0, 89600.0, 89800.0, 90000.0, 90200.0, 90400.0, 90600.0, 90800.0, 91000.0, 91200.0], \"y\": [0.09982825815677643, 0.08992502838373184, 0.03833387792110443, 0.019846154376864433, 0.014690927229821682, 0.012804585509002209, 0.009597797878086567, 0.00897055771201849, 0.006471734493970871, 0.008355860598385334, 0.005969693418592215, 0.004501638934016228, 0.005738754291087389, 0.004545500036329031, 0.005133424885571003, 0.007848013192415237, 0.005817303899675608, 0.0038887509144842625, 0.005380994640290737, 0.003365126671269536, 0.003884510602802038, 0.002982339821755886, 0.0039657908491790295, 0.0038417892064899206, 0.004687155596911907, 0.005711769685149193, 0.004514370113611221, 0.002508781151846051, 0.003322915406897664, 0.005034629721194506, 0.003608274506404996, 0.003282000310719013, 0.0032325529027730227, 0.0028356672264635563, 0.002343150321394205, 0.003259610151872039, 0.003838069038465619, 0.004047464579343796, 0.002793861785903573, 0.0033053632359951735, 0.002785539021715522, 0.002351125469431281, 0.0011018523946404457, 0.003327626269310713, 0.0014367743860930204, 0.0024256964679807425, 0.00263962778262794, 0.0026536881923675537, 0.002448467770591378, 0.0020995216909796, 0.002224134048447013, 0.0035898122005164623, 0.002662225626409054, 0.003382493741810322, 0.0036875256337225437, 0.0012970154639333487, 0.0025756412651389837, 0.0023525976575911045, 0.003074686275795102, 0.003983930218964815, 0.0028668344020843506, 0.0014079547254368663, 0.0020989933982491493, 0.0009791876655071974, 0.0027901558205485344, 0.0015891542425379157, 0.0018014045199379325, 0.0017058310331776738, 0.0028710155747830868, 0.0016030650585889816, 0.0009073832770809531, 0.001302790711633861, 0.0015826411545276642, 0.0025531412102282047, 0.001993748592212796, 0.0013122993987053633, 0.0009347574668936431, 0.0015473348321393132, 0.0018171811243519187, 0.0028685436118394136, 0.0015798945678398013, 0.0007525735418312252, 0.0012130595277994871, 0.0012907532509416342, 0.0012718327343463898, 0.0017461233073845506, 0.0019364882027730346, 0.0011295771691948175, 0.0010143147082999349, 0.0029381471686065197, 0.0035931116435676813, 0.00081012980081141, 0.0017568552866578102, 0.0008182203164324164, 0.002232236322015524, 0.0004904409288428724, 0.002640628255903721, 0.0006130975671112537, 0.0012349880998954177, 0.0017470002640038729, 0.0016588115831837058, 0.0017698227893561125, 0.0008224096382036805, 0.0014911529142409563, 0.001700543682090938, 0.0020264398772269487, 0.0013217083178460598, 0.0018333770567551255, 0.001484185690060258, 0.0017677188152447343, 0.0018302793614566326, 0.0017767890822142363, 0.0008182362071238458, 0.0014440699014812708, 0.0021909999195486307, 0.0014221521560102701, 0.0012596866581588984, 0.0019383151084184647, 0.0018782838014885783, 0.0008897940278984606, 0.0010535467881709337, 0.0013942262157797813, 0.001768046640790999, 0.0010537953348830342, 0.00128702144138515, 0.001180575811304152, 0.003010484389960766, 0.0025537440087646246, 0.002245714422315359, 0.0009801086271181703, 0.0013102232478559017, 0.0007812926196493208, 0.0009798785904422402, 0.001425801427103579, 0.0010011059930548072, 0.0013287157053127885, 0.0013019638136029243, 0.0022151803132146597, 0.0008646181668154895, 0.000769111153203994, 0.0026224174071103334, 0.0006148067186586559, 0.0009587909444235265, 0.00121422263327986, 0.0003932006366085261, 0.0012115852441638708, 0.0005931909545324743, 0.0005572829395532608, 0.0009270255686715245, 0.0003833514347206801, 0.0009527528891339898, 0.0005170574295334518, 0.0009012797963805497, 0.0023774360306560993, 0.0017641077283769846, 0.0009831479983404279, 0.0021358097437769175, 0.0010837387526407838, 0.0010734094539657235, 0.0012807641178369522, 0.001099580549634993, 0.0013626489089801908, 0.0006419931887649, 0.0008760448545217514, 0.0008043097914196551, 0.0006054864497855306, 0.001095202169381082, 0.0019819748122245073, 0.0003823263687081635, 0.0009948930237442255, 0.00040904045454226434, 0.0019707242026925087, 0.0010846969671547413, 0.0005969310877844691, 0.0005859819939360023, 0.0005787317641079426, 0.0009669594583101571, 0.001123539637774229, 0.0013899228069931269, 0.0009360566036775708, 0.00095338374376297, 0.0009056426933966577, 0.0019501809729263186, 0.0008881118264980614, 0.0008021827670745552, 0.0009448446216993034, 0.0009098314330913126, 0.0009853715309873223, 0.0009003370068967342, 0.0013660427648574114, 0.00030933591187931597, 0.001042822957970202, 0.0010705071035772562, 0.0006330822361633182, 0.000686360988765955, 0.0011997349793091416, 0.00042055503581650555, 0.0008003134862519801, 0.000638218189124018, 0.000720321957487613, 0.0007456092862412333, 0.0007241753628477454, 0.0006137548480182886, 0.0007949175196699798, 0.0005866067367605865, 0.0002681682235561311, 0.0006623548688367009, 0.0008493222412653267, 0.0014163402374833822, 0.0005795859615318477, 0.0010272663785144687, 0.00035547875449992716, 0.0010011795675382018, 0.0006844616727903485, 0.001340547576546669, 0.0013233822537586093, 0.0003961938200518489, 0.0011098047252744436, 0.0010969866998493671, 0.0017964838771149516, 0.00047168415039777756, 0.0010170878376811743, 0.00034984329249709845, 0.0007064510718919337, 0.0017732195556163788, 0.001266288454644382, 0.0010568209690973163, 0.000511987367644906, 0.0021075971890240908, 0.0017183867748826742, 0.0010817982256412506, 0.0006556865409947932, 0.0008776644244790077, 0.0005250608664937317, 0.000404463178711012, 0.0004871460550930351, 0.000350016460288316, 0.000805498450063169, 0.0008309207623824477, 0.0017273792764171958, 0.001048704027198255, 0.0002129222557414323, 0.0015122521435841918, 0.0010178283555433154, 0.000527719035744667, 0.0013625748688355088, 0.00030603448976762593, 0.0006039010477252305, 0.00035679570282809436, 0.0016787286149337888, 0.0013231165939942002, 0.0003124876820947975, 0.0008437117794528604, 0.001033079344779253, 0.0014791692374274135, 0.000267607974819839, 0.0005424085538834333, 0.0008583485032431781, 0.00038442149525508285, 0.0006411589565686882, 0.0008517670794390142, 0.0010012493003159761, 0.001036929665133357, 0.00023398635676130652, 0.0011176461121067405, 0.0001837071613408625, 0.0002715095761232078, 0.0008789515704847872, 0.0005100186099298298, 0.0007000561454333365, 0.0008711919072084129, 0.00043502484913915396, 0.000354730524122715, 0.0007161293760873377, 0.00029012328013777733, 0.001384928124025464, 0.00016534152382519096, 0.000967650965321809, 0.0013266532914713025, 0.0003916605201084167, 0.0007726634503342211, 0.0005063456483185291, 0.0009657324990257621, 0.00042394702904857695, 0.0002147962077287957, 0.0008941460982896388, 0.00020261984900571406, 0.0003341849660500884, 0.001354689011350274, 0.001569501357153058, 0.0003551356785465032, 0.0011179129360243678, 0.0008422164828516543, 0.0004565351700875908, 0.0010076864855363965, 0.0010883761569857597, 0.0006259334040805697, 0.0008488188032060862, 0.0003771606716327369, 0.0004942197119817138, 0.0002940972335636616, 0.0005191115778870881, 0.0010448571993038058, 0.0003414173552300781, 0.0007909860578365624, 0.000840348657220602, 0.0005116944084875286, 0.0008500748663209379, 0.0003594367590267211, 0.000479974813060835, 0.0007206284790299833, 0.0005032623885199428, 0.0009809356415644288, 0.0007995071937330067, 0.0011895281495526433, 0.0004544459516182542, 0.00027385889552533627, 0.0006523439660668373, 0.0003942220937460661, 0.0009211997385136783, 0.0003075633430853486, 0.0007370958337560296, 0.0011017433134838939, 0.00037646721466444433, 0.0011339850025251508, 0.0013143495889380574, 0.0014623472234234214, 0.0009329527383670211, 0.0014442414976656437, 0.0008898079977370799, 0.0005020669777877629, 0.0014202800812199712, 0.0022234225180000067, 0.001596585614606738, 0.00032724521588534117, 0.0007834550342522562, 0.00013204132847022265, 0.0008186075720004737, 0.00026182629517279565, 0.00028603558894246817, 0.001938491826876998, 0.0010086871916428208, 0.0006616893806494772, 0.0004933649906888604, 0.00028608072898350656, 0.0006512743420898914, 0.0005651499959640205, 0.0006584650836884975, 0.000595666526351124, 0.00020961358677595854, 0.0008987976470962167, 0.00048192794201895595, 0.00031503886566497386, 0.0005924026481807232, 0.00033207586966454983, 0.0005130236968398094, 0.00024785238201729953, 0.000543446047231555, 0.0006044250912964344, 0.0009226577240042388, 0.0007645290461368859, 0.0005501311388798058, 0.0008333532023243606, 0.000804304436314851, 0.0005774781457148492, 0.001005694386549294, 0.00043416611151769757, 0.0002168744831578806, 0.00028917379677295685, 0.00021790126629639417, 0.00024792581098154187, 0.0003734096826519817, 0.0003140481421723962, 0.0002440188982291147, 0.001883504563011229, 0.0007135228952392936, 0.0006246534758247435, 0.0011099668918177485, 0.0006187111139297485, 0.00014589063357561827, 0.0010522996308282018, 0.0003064074262510985, 0.00018801327678374946, 0.00018569594249129295, 0.000512988306581974, 0.0015535133425146341, 0.0004120526718907058, 0.00037665513809770346, 0.0013763847528025508, 0.0015507431235164404, 0.0003722166293300688, 0.0004251455538906157, 0.0006939004524610937, 0.0004083884123247117, 0.00020204314205329865, 0.0004574054037220776, 0.0009591639973223209, 0.00030773223261348903, 0.0004668283509090543, 0.0006481885793618858, 0.00011720089241862297, 0.00023329895338974893, 0.00018487262423150241, 0.00047996893408708274, 0.0010425143409520388, 0.0008425042033195496, 0.000461757619632408, 0.0001504814572399482, 0.00046332221245393157, 0.0002981995639856905, 0.00043796043610200286, 0.0005487558082677424, 0.00035661656875163317, 0.00014591685612685978, 0.0010125681292265654, 0.0002606864436529577, 0.00035916976048611104, 0.00036607691436074674, 0.0006782840355299413, 0.00048415048513561487, 0.00024752403260208666, 0.0006531815743073821, 0.0005018160445615649, 0.00014604245370719582, 0.0010976288467645645, 0.0003817034885287285, 0.0006445100880227983, 0.0008858448709361255, 0.0006809182814322412, 0.001000251155346632, 0.0002250353863928467, 0.00027052941732108593, 0.0013490088749676943, 0.0009020438883453608, 0.0002971063950099051, 0.0001708257623249665, 0.00018380778783466667, 0.0005502503481693566, 0.0009314780472777784, 0.0003072369145229459, 0.0005381049122661352, 0.0009282746468670666, 0.0006999557954259217, 0.0011442000977694988, 0.0007208707393147051, 0.0011853550095111132, 0.00030075671384111047, 0.00012627712567336857, 0.0005602711462415755, 0.00018954901315737516, 0.0007175737409852445, 0.0006842142902314663, 0.001582951983436942, 0.00030367716681212187, 0.0002816766791511327, 0.0002035229845205322, 0.0004748672363348305]}], {\"title\": \"Model Loss vs. Epochs\", \"xaxis\": {\"title\": \"Epochs\"}, \"yaxis\": {\"title\": \"Loss\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"a7a2224e-19b1-4deb-96d3-3768a0460b04\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"a7a2224e-19b1-4deb-96d3-3768a0460b04\", [{\"type\": \"scatter\", \"x\": [0.0, 200.0, 400.0, 600.0, 800.0, 1000.0, 1200.0, 1400.0, 1600.0, 1800.0, 2000.0, 2200.0, 2400.0, 2600.0, 2800.0, 3000.0, 3200.0, 3400.0, 3600.0, 3800.0, 4000.0, 4200.0, 4400.0, 4600.0, 4800.0, 5000.0, 5200.0, 5400.0, 5600.0, 5800.0, 6000.0, 6200.0, 6400.0, 6600.0, 6800.0, 7000.0, 7200.0, 7400.0, 7600.0, 7800.0, 8000.0, 8200.0, 8400.0, 8600.0, 8800.0, 9000.0, 9200.0, 9400.0, 9600.0, 9800.0, 10000.0, 10200.0, 10400.0, 10600.0, 10800.0, 11000.0, 11200.0, 11400.0, 11600.0, 11800.0, 12000.0, 12200.0, 12400.0, 12600.0, 12800.0, 13000.0, 13200.0, 13400.0, 13600.0, 13800.0, 14000.0, 14200.0, 14400.0, 14600.0, 14800.0, 15000.0, 15200.0, 15400.0, 15600.0, 15800.0, 16000.0, 16200.0, 16400.0, 16600.0, 16800.0, 17000.0, 17200.0, 17400.0, 17600.0, 17800.0, 18000.0, 18200.0, 18400.0, 18600.0, 18800.0, 19000.0, 19200.0, 19400.0, 19600.0, 19800.0, 20000.0, 20200.0, 20400.0, 20600.0, 20800.0, 21000.0, 21200.0, 21400.0, 21600.0, 21800.0, 22000.0, 22200.0, 22400.0, 22600.0, 22800.0, 23000.0, 23200.0, 23400.0, 23600.0, 23800.0, 24000.0, 24200.0, 24400.0, 24600.0, 24800.0, 25000.0, 25200.0, 25400.0, 25600.0, 25800.0, 26000.0, 26200.0, 26400.0, 26600.0, 26800.0, 27000.0, 27200.0, 27400.0, 27600.0, 27800.0, 28000.0, 28200.0, 28400.0, 28600.0, 28800.0, 29000.0, 29200.0, 29400.0, 29600.0, 29800.0, 30000.0, 30200.0, 30400.0, 30600.0, 30800.0, 31000.0, 31200.0, 31400.0, 31600.0, 31800.0, 32000.0, 32200.0, 32400.0, 32600.0, 32800.0, 33000.0, 33200.0, 33400.0, 33600.0, 33800.0, 34000.0, 34200.0, 34400.0, 34600.0, 34800.0, 35000.0, 35200.0, 35400.0, 35600.0, 35800.0, 36000.0, 36200.0, 36400.0, 36600.0, 36800.0, 37000.0, 37200.0, 37400.0, 37600.0, 37800.0, 38000.0, 38200.0, 38400.0, 38600.0, 38800.0, 39000.0, 39200.0, 39400.0, 39600.0, 39800.0, 40000.0, 40200.0, 40400.0, 40600.0, 40800.0, 41000.0, 41200.0, 41400.0, 41600.0, 41800.0, 42000.0, 42200.0, 42400.0, 42600.0, 42800.0, 43000.0, 43200.0, 43400.0, 43600.0, 43800.0, 44000.0, 44200.0, 44400.0, 44600.0, 44800.0, 45000.0, 45200.0, 45400.0, 45600.0, 45800.0, 46000.0, 46200.0, 46400.0, 46600.0, 46800.0, 47000.0, 47200.0, 47400.0, 47600.0, 47800.0, 48000.0, 48200.0, 48400.0, 48600.0, 48800.0, 49000.0, 49200.0, 49400.0, 49600.0, 49800.0, 50000.0, 50200.0, 50400.0, 50600.0, 50800.0, 51000.0, 51200.0, 51400.0, 51600.0, 51800.0, 52000.0, 52200.0, 52400.0, 52600.0, 52800.0, 53000.0, 53200.0, 53400.0, 53600.0, 53800.0, 54000.0, 54200.0, 54400.0, 54600.0, 54800.0, 55000.0, 55200.0, 55400.0, 55600.0, 55800.0, 56000.0, 56200.0, 56400.0, 56600.0, 56800.0, 57000.0, 57200.0, 57400.0, 57600.0, 57800.0, 58000.0, 58200.0, 58400.0, 58600.0, 58800.0, 59000.0, 59200.0, 59400.0, 59600.0, 59800.0, 60000.0, 60200.0, 60400.0, 60600.0, 60800.0, 61000.0, 61200.0, 61400.0, 61600.0, 61800.0, 62000.0, 62200.0, 62400.0, 62600.0, 62800.0, 63000.0, 63200.0, 63400.0, 63600.0, 63800.0, 64000.0, 64200.0, 64400.0, 64600.0, 64800.0, 65000.0, 65200.0, 65400.0, 65600.0, 65800.0, 66000.0, 66200.0, 66400.0, 66600.0, 66800.0, 67000.0, 67200.0, 67400.0, 67600.0, 67800.0, 68000.0, 68200.0, 68400.0, 68600.0, 68800.0, 69000.0, 69200.0, 69400.0, 69600.0, 69800.0, 70000.0, 70200.0, 70400.0, 70600.0, 70800.0, 71000.0, 71200.0, 71400.0, 71600.0, 71800.0, 72000.0, 72200.0, 72400.0, 72600.0, 72800.0, 73000.0, 73200.0, 73400.0, 73600.0, 73800.0, 74000.0, 74200.0, 74400.0, 74600.0, 74800.0, 75000.0, 75200.0, 75400.0, 75600.0, 75800.0, 76000.0, 76200.0, 76400.0, 76600.0, 76800.0, 77000.0, 77200.0, 77400.0, 77600.0, 77800.0, 78000.0, 78200.0, 78400.0, 78600.0, 78800.0, 79000.0, 79200.0, 79400.0, 79600.0, 79800.0, 80000.0, 80200.0, 80400.0, 80600.0, 80800.0, 81000.0, 81200.0, 81400.0, 81600.0, 81800.0, 82000.0, 82200.0, 82400.0, 82600.0, 82800.0, 83000.0, 83200.0, 83400.0, 83600.0, 83800.0, 84000.0, 84200.0, 84400.0, 84600.0, 84800.0, 85000.0, 85200.0, 85400.0, 85600.0, 85800.0, 86000.0, 86200.0, 86400.0, 86600.0, 86800.0, 87000.0, 87200.0, 87400.0, 87600.0, 87800.0, 88000.0, 88200.0, 88400.0, 88600.0, 88800.0, 89000.0, 89200.0, 89400.0, 89600.0, 89800.0, 90000.0, 90200.0, 90400.0, 90600.0, 90800.0, 91000.0, 91200.0], \"y\": [0.09982825815677643, 0.08992502838373184, 0.03833387792110443, 0.019846154376864433, 0.014690927229821682, 0.012804585509002209, 0.009597797878086567, 0.00897055771201849, 0.006471734493970871, 0.008355860598385334, 0.005969693418592215, 0.004501638934016228, 0.005738754291087389, 0.004545500036329031, 0.005133424885571003, 0.007848013192415237, 0.005817303899675608, 0.0038887509144842625, 0.005380994640290737, 0.003365126671269536, 0.003884510602802038, 0.002982339821755886, 0.0039657908491790295, 0.0038417892064899206, 0.004687155596911907, 0.005711769685149193, 0.004514370113611221, 0.002508781151846051, 0.003322915406897664, 0.005034629721194506, 0.003608274506404996, 0.003282000310719013, 0.0032325529027730227, 0.0028356672264635563, 0.002343150321394205, 0.003259610151872039, 0.003838069038465619, 0.004047464579343796, 0.002793861785903573, 0.0033053632359951735, 0.002785539021715522, 0.002351125469431281, 0.0011018523946404457, 0.003327626269310713, 0.0014367743860930204, 0.0024256964679807425, 0.00263962778262794, 0.0026536881923675537, 0.002448467770591378, 0.0020995216909796, 0.002224134048447013, 0.0035898122005164623, 0.002662225626409054, 0.003382493741810322, 0.0036875256337225437, 0.0012970154639333487, 0.0025756412651389837, 0.0023525976575911045, 0.003074686275795102, 0.003983930218964815, 0.0028668344020843506, 0.0014079547254368663, 0.0020989933982491493, 0.0009791876655071974, 0.0027901558205485344, 0.0015891542425379157, 0.0018014045199379325, 0.0017058310331776738, 0.0028710155747830868, 0.0016030650585889816, 0.0009073832770809531, 0.001302790711633861, 0.0015826411545276642, 0.0025531412102282047, 0.001993748592212796, 0.0013122993987053633, 0.0009347574668936431, 0.0015473348321393132, 0.0018171811243519187, 0.0028685436118394136, 0.0015798945678398013, 0.0007525735418312252, 0.0012130595277994871, 0.0012907532509416342, 0.0012718327343463898, 0.0017461233073845506, 0.0019364882027730346, 0.0011295771691948175, 0.0010143147082999349, 0.0029381471686065197, 0.0035931116435676813, 0.00081012980081141, 0.0017568552866578102, 0.0008182203164324164, 0.002232236322015524, 0.0004904409288428724, 0.002640628255903721, 0.0006130975671112537, 0.0012349880998954177, 0.0017470002640038729, 0.0016588115831837058, 0.0017698227893561125, 0.0008224096382036805, 0.0014911529142409563, 0.001700543682090938, 0.0020264398772269487, 0.0013217083178460598, 0.0018333770567551255, 0.001484185690060258, 0.0017677188152447343, 0.0018302793614566326, 0.0017767890822142363, 0.0008182362071238458, 0.0014440699014812708, 0.0021909999195486307, 0.0014221521560102701, 0.0012596866581588984, 0.0019383151084184647, 0.0018782838014885783, 0.0008897940278984606, 0.0010535467881709337, 0.0013942262157797813, 0.001768046640790999, 0.0010537953348830342, 0.00128702144138515, 0.001180575811304152, 0.003010484389960766, 0.0025537440087646246, 0.002245714422315359, 0.0009801086271181703, 0.0013102232478559017, 0.0007812926196493208, 0.0009798785904422402, 0.001425801427103579, 0.0010011059930548072, 0.0013287157053127885, 0.0013019638136029243, 0.0022151803132146597, 0.0008646181668154895, 0.000769111153203994, 0.0026224174071103334, 0.0006148067186586559, 0.0009587909444235265, 0.00121422263327986, 0.0003932006366085261, 0.0012115852441638708, 0.0005931909545324743, 0.0005572829395532608, 0.0009270255686715245, 0.0003833514347206801, 0.0009527528891339898, 0.0005170574295334518, 0.0009012797963805497, 0.0023774360306560993, 0.0017641077283769846, 0.0009831479983404279, 0.0021358097437769175, 0.0010837387526407838, 0.0010734094539657235, 0.0012807641178369522, 0.001099580549634993, 0.0013626489089801908, 0.0006419931887649, 0.0008760448545217514, 0.0008043097914196551, 0.0006054864497855306, 0.001095202169381082, 0.0019819748122245073, 0.0003823263687081635, 0.0009948930237442255, 0.00040904045454226434, 0.0019707242026925087, 0.0010846969671547413, 0.0005969310877844691, 0.0005859819939360023, 0.0005787317641079426, 0.0009669594583101571, 0.001123539637774229, 0.0013899228069931269, 0.0009360566036775708, 0.00095338374376297, 0.0009056426933966577, 0.0019501809729263186, 0.0008881118264980614, 0.0008021827670745552, 0.0009448446216993034, 0.0009098314330913126, 0.0009853715309873223, 0.0009003370068967342, 0.0013660427648574114, 0.00030933591187931597, 0.001042822957970202, 0.0010705071035772562, 0.0006330822361633182, 0.000686360988765955, 0.0011997349793091416, 0.00042055503581650555, 0.0008003134862519801, 0.000638218189124018, 0.000720321957487613, 0.0007456092862412333, 0.0007241753628477454, 0.0006137548480182886, 0.0007949175196699798, 0.0005866067367605865, 0.0002681682235561311, 0.0006623548688367009, 0.0008493222412653267, 0.0014163402374833822, 0.0005795859615318477, 0.0010272663785144687, 0.00035547875449992716, 0.0010011795675382018, 0.0006844616727903485, 0.001340547576546669, 0.0013233822537586093, 0.0003961938200518489, 0.0011098047252744436, 0.0010969866998493671, 0.0017964838771149516, 0.00047168415039777756, 0.0010170878376811743, 0.00034984329249709845, 0.0007064510718919337, 0.0017732195556163788, 0.001266288454644382, 0.0010568209690973163, 0.000511987367644906, 0.0021075971890240908, 0.0017183867748826742, 0.0010817982256412506, 0.0006556865409947932, 0.0008776644244790077, 0.0005250608664937317, 0.000404463178711012, 0.0004871460550930351, 0.000350016460288316, 0.000805498450063169, 0.0008309207623824477, 0.0017273792764171958, 0.001048704027198255, 0.0002129222557414323, 0.0015122521435841918, 0.0010178283555433154, 0.000527719035744667, 0.0013625748688355088, 0.00030603448976762593, 0.0006039010477252305, 0.00035679570282809436, 0.0016787286149337888, 0.0013231165939942002, 0.0003124876820947975, 0.0008437117794528604, 0.001033079344779253, 0.0014791692374274135, 0.000267607974819839, 0.0005424085538834333, 0.0008583485032431781, 0.00038442149525508285, 0.0006411589565686882, 0.0008517670794390142, 0.0010012493003159761, 0.001036929665133357, 0.00023398635676130652, 0.0011176461121067405, 0.0001837071613408625, 0.0002715095761232078, 0.0008789515704847872, 0.0005100186099298298, 0.0007000561454333365, 0.0008711919072084129, 0.00043502484913915396, 0.000354730524122715, 0.0007161293760873377, 0.00029012328013777733, 0.001384928124025464, 0.00016534152382519096, 0.000967650965321809, 0.0013266532914713025, 0.0003916605201084167, 0.0007726634503342211, 0.0005063456483185291, 0.0009657324990257621, 0.00042394702904857695, 0.0002147962077287957, 0.0008941460982896388, 0.00020261984900571406, 0.0003341849660500884, 0.001354689011350274, 0.001569501357153058, 0.0003551356785465032, 0.0011179129360243678, 0.0008422164828516543, 0.0004565351700875908, 0.0010076864855363965, 0.0010883761569857597, 0.0006259334040805697, 0.0008488188032060862, 0.0003771606716327369, 0.0004942197119817138, 0.0002940972335636616, 0.0005191115778870881, 0.0010448571993038058, 0.0003414173552300781, 0.0007909860578365624, 0.000840348657220602, 0.0005116944084875286, 0.0008500748663209379, 0.0003594367590267211, 0.000479974813060835, 0.0007206284790299833, 0.0005032623885199428, 0.0009809356415644288, 0.0007995071937330067, 0.0011895281495526433, 0.0004544459516182542, 0.00027385889552533627, 0.0006523439660668373, 0.0003942220937460661, 0.0009211997385136783, 0.0003075633430853486, 0.0007370958337560296, 0.0011017433134838939, 0.00037646721466444433, 0.0011339850025251508, 0.0013143495889380574, 0.0014623472234234214, 0.0009329527383670211, 0.0014442414976656437, 0.0008898079977370799, 0.0005020669777877629, 0.0014202800812199712, 0.0022234225180000067, 0.001596585614606738, 0.00032724521588534117, 0.0007834550342522562, 0.00013204132847022265, 0.0008186075720004737, 0.00026182629517279565, 0.00028603558894246817, 0.001938491826876998, 0.0010086871916428208, 0.0006616893806494772, 0.0004933649906888604, 0.00028608072898350656, 0.0006512743420898914, 0.0005651499959640205, 0.0006584650836884975, 0.000595666526351124, 0.00020961358677595854, 0.0008987976470962167, 0.00048192794201895595, 0.00031503886566497386, 0.0005924026481807232, 0.00033207586966454983, 0.0005130236968398094, 0.00024785238201729953, 0.000543446047231555, 0.0006044250912964344, 0.0009226577240042388, 0.0007645290461368859, 0.0005501311388798058, 0.0008333532023243606, 0.000804304436314851, 0.0005774781457148492, 0.001005694386549294, 0.00043416611151769757, 0.0002168744831578806, 0.00028917379677295685, 0.00021790126629639417, 0.00024792581098154187, 0.0003734096826519817, 0.0003140481421723962, 0.0002440188982291147, 0.001883504563011229, 0.0007135228952392936, 0.0006246534758247435, 0.0011099668918177485, 0.0006187111139297485, 0.00014589063357561827, 0.0010522996308282018, 0.0003064074262510985, 0.00018801327678374946, 0.00018569594249129295, 0.000512988306581974, 0.0015535133425146341, 0.0004120526718907058, 0.00037665513809770346, 0.0013763847528025508, 0.0015507431235164404, 0.0003722166293300688, 0.0004251455538906157, 0.0006939004524610937, 0.0004083884123247117, 0.00020204314205329865, 0.0004574054037220776, 0.0009591639973223209, 0.00030773223261348903, 0.0004668283509090543, 0.0006481885793618858, 0.00011720089241862297, 0.00023329895338974893, 0.00018487262423150241, 0.00047996893408708274, 0.0010425143409520388, 0.0008425042033195496, 0.000461757619632408, 0.0001504814572399482, 0.00046332221245393157, 0.0002981995639856905, 0.00043796043610200286, 0.0005487558082677424, 0.00035661656875163317, 0.00014591685612685978, 0.0010125681292265654, 0.0002606864436529577, 0.00035916976048611104, 0.00036607691436074674, 0.0006782840355299413, 0.00048415048513561487, 0.00024752403260208666, 0.0006531815743073821, 0.0005018160445615649, 0.00014604245370719582, 0.0010976288467645645, 0.0003817034885287285, 0.0006445100880227983, 0.0008858448709361255, 0.0006809182814322412, 0.001000251155346632, 0.0002250353863928467, 0.00027052941732108593, 0.0013490088749676943, 0.0009020438883453608, 0.0002971063950099051, 0.0001708257623249665, 0.00018380778783466667, 0.0005502503481693566, 0.0009314780472777784, 0.0003072369145229459, 0.0005381049122661352, 0.0009282746468670666, 0.0006999557954259217, 0.0011442000977694988, 0.0007208707393147051, 0.0011853550095111132, 0.00030075671384111047, 0.00012627712567336857, 0.0005602711462415755, 0.00018954901315737516, 0.0007175737409852445, 0.0006842142902314663, 0.001582951983436942, 0.00030367716681212187, 0.0002816766791511327, 0.0002035229845205322, 0.0004748672363348305]}], {\"title\": \"Model Loss vs. Epochs\", \"xaxis\": {\"title\": \"Epochs\"}, \"yaxis\": {\"title\": \"Loss\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotly.iplot(cnn.monitors[0].plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99767272727272727"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = cnn.predict(train_in.reshape((110000, 28, 28, 1)))\n",
    "np.sum(train_pred.argmax(axis=1) == train_labels.argmax(axis=1)) / train_in.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97940000000000005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = cnn.predict(test_in.reshape((20000, 28, 28, 1)))\n",
    "np.sum(train_pred.argmax(axis=1) == test_labels.argmax(axis=1)) / test_in.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exploring CNN Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filters_1 = cnn.session.run(cnn.lc[0]['filter'])\n",
    "\n",
    "def feed_forwards(self, input_vector, n):    \n",
    "    for i in range(n):\n",
    "        lc = self.lc[i]\n",
    "\n",
    "        if lc['layer_type'] == 'conv':\n",
    "            input_vector = tf.nn.conv2d(\n",
    "                input=input_vector,\n",
    "                filter=lc['filter'],\n",
    "                strides=lc['stride_size'],\n",
    "                padding='VALID'\n",
    "            )\n",
    "            input_vector = lc['activation'](input_vector)\n",
    "\n",
    "        elif lc['layer_type'] == 'conv_transpose':\n",
    "            input_vector = tf.nn.conv2d_transpose(\n",
    "                value=input_vector,\n",
    "                filter=lc['filter'],\n",
    "                output_shape=lc['output_size'],\n",
    "                strides=lc['stride_size']\n",
    "            )\n",
    "            input_vector = lc['activation'](input_vector)\n",
    "\n",
    "        elif lc['layer_type'] == 'connected':\n",
    "            a = lc['activation']\n",
    "            w = lc['weights']\n",
    "            b = lc['biases']\n",
    "            input_vector = a(tf.matmul(input_vector, w) + b)\n",
    "\n",
    "        elif lc['layer_type'] == 'pool':\n",
    "            if lc['pool_type'] == 'average':\n",
    "                input_vector = tf.nn.avg_pool(\n",
    "                    value=input_vector,\n",
    "                    ksize=lc['pool_size'],\n",
    "                    strides=lc['stride_size'],\n",
    "                    padding='SAME'\n",
    "                )\n",
    "            elif lc['pool_type'] == 'max':\n",
    "                input_vector = tf.nn.max_pool(\n",
    "                    value=input_vector,\n",
    "                    ksize=lc['pool_size'],\n",
    "                    strides=lc['stride_size'],\n",
    "                    padding='SAME'\n",
    "                )\n",
    "\n",
    "        elif lc['layer_type'] == 'reshape':\n",
    "            input_vector = tf.reshape(input_vector, [-1] + lc['new_shape'])\n",
    "            \n",
    "    return input_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAAAAACi5bZQAAADd0lEQVR4nO3dL4ilZRyG4VEEg2IR\ntG4ZsQhqEUEQEUHEbrG5Wl0MFptrEbRoEZNRxOqCabGZDILFJiyaFXFB8E/7vcHvHgbOOXNGva70\nsDN75nDzhpfDtzsnJwAAAAAAAAAAAAAAAAAAAAAAAAC7uOPYb+Dk5O5ZD8x6ZdaLsx4781VuzHpp\n1m87vKs7d/i7/2nCBGGCMEGYIEwQJggThAkXcvO9f9ZDs56e9eysZzb+7nqDf535M9b3rZvv5+d6\nd9ucmCBMECYIE4QJwgRhgjBBmHDX4V76kVmfzTqddd4b7XndnnVrL6/nxARhgjBBmCBMECYIE4QJ\nwoQD3nzvnXV6xnfty7uzvt7L6zkxQZggTBAmCBOECcIEYYIw4YA336uz1ue7P826Oev6rO9nvTrr\n4VnXNn7Gr7NubHx1F05MECYIE4QJwgRhgjBBmCBMOOBzvuvp3vX87hezbp+cz/uzXt/46nOzbm58\ndRdOTBAmCBOECcIEYYIwQZggTLgE/7fDlvUv4daN9sFZH816Y9bve34HTkwQJggThAnCBGGCMEGY\nIEy4pDff72atpx1+nPXUrB8O9g6cmCBMECYIE4QJwgRhgjBBmHDA53zPa/1/vh/OWvfdX2Z9POtw\n993FiQnCBGGCMEGYIEwQJggThAlH+8z3yqw3Z7228X0vz/r0gO/mn5yYIEwQJggThAnCBGGCMEGY\ncMGf+a7nd9+b9cLG963/7+Fi77uLExOECcIEYYIwQZggTBAmCBMu+DPfred312+yWPfdd2b9ceB3\nVJyYIEwQJggThAnCBGGCMEGYcMDPfK/M+mDWuu/+OevtWevme3xOTBAmCBOECcIEYYIwQZggTDjg\nzffxWet5hvX57uW87y5OTBAmCBOECcIEYYIwQZggTNj7zXf9vom3Nr56fWNdTk5MECYIE4QJwgRh\ngjBBmCBM2NNzvuu3Da9/uXbPrPVbiZ+c9fN+fvDBODFBmCBMECYIE4QJwgRhgjBhp5vvo7O+mnXf\nrC9nPb/LDzkSJyYIE4QJwgRhgjBBmCBMECbs9LTDtVnr891vZ13d5aWPzokJwgRhgjBBmCBMECYI\nE4QJO918Tzf+7JNZt3Z56aNzYoIwQZggTBAmCBOECcIEYcJON99vZj2x8Wf/bk5MECYIE4QJwgRh\ngjBBmCAMAAD8r/0NF6051iAsNFAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=280x280 at 0x7F4DC4FD1588>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1\n",
    "image = train_in.reshape((110000, 28, 28, 1))[n:n+1, :, :, :]\n",
    "\n",
    "f1 = np.repeat(image[0,:,:,0], 10, 0)\n",
    "f1 = np.repeat(f1, 10, 1)\n",
    "Image.fromarray((255 * (f1 - f1.min()) / (f1.max() - f1.min())).astype('uint8'), mode='L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAAEZ0lEQVR4nO2dT29VVRxFX7GiBrQE\njFCiYmKcqBAYGXTCSAkycObX6AQcOGgwMvVLGE38AM6IhIiaSBQIiKkGaJFgACNPbFMVqsz2MvZn\nedzXP8k+e41W+npf7+6Z7Jxz7rkjk722WLfWN7DaJLA7CexOAruTwO4ksDsJ7E4Cu5PA7iSwOwns\nTgK7k8DuJLA7CezO6Mp99YhsQTYnOyf7UfZbcQXfskH2mmyPbL1sVvZPcVfNjXACu5PA7iSwOwns\nzlBNixY0L/tFNi37SXZb9mfxLQ/LHpHdkdGgrstuFldsLK6F5kY4gd1JYHcS2J0EdqdD06IZ9WXH\nZD/LmJd6SHa3MKCvjRSf8rMnZHQz5q9oZLQvaG6EE9idBHYngd1JYHc6NK1HZVtkt2TVXNVfMtpX\ntbJHIxstfvas7IjshuwLWTWTBc2NcAK7k8DuJLA7CexOh6ZFR/pMRuOhGT0u2yzbKuvL2J3FnFZ1\n7cey54tvYRfX17Lfe4tpboQT2J0EdieB3Ulgdzo0LVoQrYp1uldkNLIdspdkNCPWEb+UzcgOyp6R\nVXvtny6uTdPqJbA/CexOAruTwO50aFpnZedl/N9Y43td9qrsbxnzV5/Kvpe9LHtbxtOFrFAuFD/r\nL7rjf9PcCCewOwnsTgK7k8DuDLV6SPd5UrZX9pxsTFb1qw9ktKX3ZcxV8Xf5FvZkTcl4+rGiuRFO\nYHcS2J0EdieB3enQtNhXtU3G+iD7qrbLmHn6SvZu8X2sKFZPDf4hY72xL5vpDUZzI5zA7iSwOwns\nTgK706FpvSDj2cOnZJx19ZGM/fIfyuhX3MI+2W4Zzy1y6in7r07Kfv2fu/0vzY1wAruTwO4ksDsJ\n7E6HpsUZVjxJyB71adk3MnZ2cRoEV7woe0fGuiRNi5msH2ScXDoozY1wAruTwO4ksDsJ7M4yvY2H\nM7Y4+eG0bL63mHHZezLWILktmhYt7TsZ65KD0twIJ7A7CexOAruTwO4MdUY879Zh1upbGf2K0yDY\nOT8p2ynjPTrMX7EqyJOJrCM+OM2NcAK7k8DuJLA7CexOh6bFyh4Xs9N9rviU+avDsgMy3q3DGRDV\n2e+D7nlfmuZGOIHdSWB3EtidBHZn4KbFTBZzSydk1X4pds5PyPbLxnqLYX3wjGx5+hU0N8IJ7E4C\nu5PA7iSwO/dpWvQrnin8XHZNxmwUTyEeku2T8bQiO6w4/4o99BeWvq0haG6EE9idBHYngd1JYHfK\npkW/okEdl10tPmUF8KiMM+KrN+9U/Yqd7itHcyOcwO4ksDsJ7E4Cu1M2rcdkp2SXZcxG0aDekr2x\n5J9bq34FzY1wAruTwO4ksDsJ7E7ZtDbJeJKQN+VwyZsyTnxndgs4aZSTH1a3X0FzI5zA7iSwOwns\nTgK7UzYtWlW10503EU7Ixovfm5VdkU0Vv7e6NDfCCexOAruTwO4ksDtl07okY8cW58F/Itsl4+ws\n5q8uynhGce1pboQT2J0EdieB3Ulgd+4BXtalzDLquCkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=240x240 at 0x7F4DC4F57080>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = cnn.session.run(feed_forwards(cnn, cnn.input, 1), {cnn.input: image})[0, :, :, 2]\n",
    "f1 = np.repeat(f, 10, 0)\n",
    "f1 = np.repeat(f1, 10, 1)\n",
    "Image.fromarray((255 * (f1 - f1.min()) / (f1.max() - f1.min())).astype('uint8'), mode='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAACWCAAAAAAZai4+AAABCElEQVR4nO3QoU2eAQBFUUo+3QHY\nAM0CBNkJ2KCroSEkOEjQuPqmQXcFYIOXHMUv7rHP3Lwfn2fL/Vwv53o318e5ns/125QlyhJlibJE\nWaIsUZYoS5QlyhJlibJEWaIscTzN+X2uV3P9M9fruZ7oW2WJskRZoixRlihLlCXKEmWJskRZoixR\nlihLHG9z/j/Xj7n+m+vFXE/0rbJEWaIsUZYoS5QlyhJlibJEWaIsUZYoS5Qljr9z/j3X57n+nOvt\nXE/0rbJEWaIsUZYoS5QlyhJlibJEWaIsUZYoS5Qljps5P8z1Za6vc/011xN9qyxRlihLlCXKEmWJ\nskRZoixRlihLlCXKEmWJL/JgEC1CL9ZSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=150x150 at 0x7F4DC4FD1C18>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = np.repeat(filters_1[:,:,0,2], 30, 0)\n",
    "f1 = np.repeat(f1, 30, 1)\n",
    "f1 = f1\n",
    "Image.fromarray((255 * (f1 - f1.min()) / (f1.max() - f1.min())).astype('uint8'), mode='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAAEgklEQVR4nO2dTYiWVRiGHU1HzZ+h\nQCxDxxSzHw0tEnThRiTDbQTRQjeKCynaSJsKgja6aJUbpUW7VJBahLqZlZkoTmWRYvRR+VeSo6b5\nN9buutU5jjPv6Azc575WF47v+733dzYP5znf87Z9MKouRo/0Aww3CexOAruTwO4ksDsJ7E4Cu5PA\n7iSwOwnsTgK7k8DuJLA7CexOArvzyMO7tb7L8VgnNg+bVvh/F7EWthPrxs5hj2KvYmP7fapKSGB3\nEtidBHYngd0ZUqU1DpuKzcBmYaqlJhauVT2kb39y4Vp9xkfYT9g1bDb2Qt9Hrm+FE9idBHYngd1J\nYHcaVFqqgl7GtEPVgamCUhXUi53BvsI+L/xV/IddwW5gN7ELhWtFdSucwO4ksDsJ7E4Cu9Og0mrH\nnsAex7RXpdpnM7YLO42pWtK3r7v0FqxUuU3B5vZ95NuoboUT2J0EdieB3UlgdxpUWh3Yn9h1rAdb\ni50o3EVnslZg6zBVad9hX2ItTFXa69gzhWcR1a1wAruTwO4ksDsJ7E6DSus49i12GfsF+71wbRum\n3uJS7BXsX+xXTPtc2r9ahr2J6exWT+EJqlvhBHYngd1JYHcS2J0GldYP2DeY+nnaZVJH8TVsDfYc\nplPyQl3B3Zgqt0nYeuwWlnNad5DA7iSwOwnsTgK7M6Tu4fOYzsZ3Yiux6Zj2pcYU7nwV24apvtIc\nh03YY9hBTOflS1S3wgnsTgK7k8DuJLA7DSotVTfzsYWYpjKoU6heoPaq9MGanfUF9gk2AVuAqd/Y\nwv66x9PeTXUrnMDuJLA7CexOArvToNJS7067RzpNpdPvz2Kaa6WP02mqj7E9mHqBquE2YH9jP2Kq\n5vqnuhVOYHcS2J0EdieB3WlQabUV/k0n4lUZqbeoE+ya6f4udgDTLw7Vb3wHm4mpU/hPfw9apLoV\nTmB3EtidBHYngd15QG/jeRFTpaWZ7jp/tQrTLxjVUdRU+U8xzURtYZrFpWmmA6W6FU5gdxLYnQR2\nJ4HdaVBplU5O6cSWeovnsbcw9QyFTnZtxdR5/A37GdP0rsFT3QonsDsJ7E4Cu5PA7gzpt4fab1J/\nUDMW3sO6CnfR+xG1f6X66iR2qHDnoVDdCiewOwnsTgK7k8DuDLjS0impRZh2t1rY+9heTD0+9Qc/\nw+ZgetthN/Zg6itR3QonsDsJ7E4Cu5PA7tyn0tLO0xLsKUxn43dgXZh6fNrx2o7p7YQ6daX9q4HO\nbBg81a1wAruTwO4ksDsJ7E6x0pqMaf9Kb5PWDtXX2IeYJj9o7tYW7GnsFDYc9ZWoboUT2J0EdieB\n3Ulgd4qV1mxM1ZLet3MU24ipx6f3Geqdz8sxvZN6eOsrUd0KJ7A7CexOAruTwO4UK612TPOqjmH7\nsUuFK1ZjmpilaVtHsOGtr0R1K5zA7iSwOwnsTgK7U6y0NHn9D6x0ql2n5DXT/Q1Mc0i/x0aqvhLV\nrXACu5PA7iSwOwnsTrHS2odp2sJL2GLsbews9iR2GNMbekae6lY4gd1JYHcS2J0Edud/0NeY182Q\nX3AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=240x240 at 0x7F4DC4F57C50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = cnn.session.run(feed_forwards(cnn, cnn.input, 1), {cnn.input: image})[0, :, :, 0]\n",
    "f1 = np.repeat(f, 10, 0)\n",
    "f1 = np.repeat(f1, 10, 1)\n",
    "Image.fromarray((255 * (f1 - f1.min()) / (f1.max() - f1.min())).astype('uint8'), mode='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAACWCAAAAAAZai4+AAABBElEQVR4nO3YITIFABhFYc8wiiQI\nqmwBNqvbAYKxBMkOCLoZ0Q7uzEle+L56y5k//of3k+Vnrt9zvZ/rw1xP5/pvZBWyClmFrEJWIauQ\nVcgqZBWyClmFrEJWIas4O5/zx1yv5/o816+5Hum1ZBWyClmFrEJWIauQVcgqZBWyClmFrEJWIas4\ne53z41w/53o115u5Hum1ZBWyClmFrEJWIauQVcgqZBWyClmFrEJWIas47M/J01zv5vo717e5Hum1\nZBWyClmFrEJWIauQVcgqZBWyClmFrEJWIas47PllrpdzvZ3rxVyP9FqyClmFrEJWIauQVcgqZBWy\nClmFrEJWIauQVfwBGlINYw3ZEAUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=150x150 at 0x7F4DC4F57208>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = np.repeat(filters_1[:,:,0,0], 30, 0)\n",
    "f1 = np.repeat(f1, 30, 1)\n",
    "f1 = f1\n",
    "Image.fromarray((255 * (f1 - f1.min()) / (f1.max() - f1.min())).astype('uint8'), mode='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAADwCAAAAAAbPrZOAAAD6klEQVR4nO2dy8vMURyHve73+y23\nEFGys7G2t/FHsLS3YiOJBUWUslUWFopCooQVkaIQUeSe+53d89mcjpnfy6jP+Tyrp3n7zczzns23\nmfM7M7RjRFuM/N9vYNAk2J0Eu5NgdxLsToLdSbA7CXYnwe4k2J0Eu5NgdxLsToLdSbA7o//dUw9h\nvwqPPcHuYY+xV9jnwrPMxhZgC7FVWGk1m1vhBLuTYHcS7E6C3RnWpKX/1k/sE/YCe4BpqnqEfcc0\nS9XRq80qvNocTBOZaG6FE+xOgt1JsDsJdqfDpKVLRmEXseuYZp+vWK+zVB19zjVU+OvY6rXNrXCC\n3UmwOwl2J8HudJi0xmAPsdPYj2G9nd5Yjk3GNPWNq17b3Aon2J0Eu5NgdxLsTodJ6xt2DBvEfKXP\nr45gmvAuYx+w0szV3Aon2J0Eu5NgdxLsTodJ6w72vO9rS7vke2UJtga7ik3E9JlbieZWOMHuJNid\nBLuTYHc6TFpXq3/Vf3AqNgnTDqt3mHZx1TmH6b7Fa5h2v+vV6u+vERLsToLdSbA7CXanw6T1qvCY\nnmYLthF7hu3CbvX4atuwudhR7CO2DKuvYXMrnGB3EuxOgt1JsDsdJq2lmHZsrcc2YV8wneOgbwBv\nVl9jJqZJ6xSmT9V0ipb2xtdpboUT7E6C3UmwOwl2p8OktQFbja3FbmP6flBnZ2laqqO9YNrfrmv1\npqdjva5ccyucYHcS7E6C3UmwOx0mrQnYCkx7rd5iuhvwJKYzR0vsw6Zhus/wdeF1+3/7za1wgt1J\nsDsJdifB7vylX+OZgZ3AzmL1+Wodthm7j10pvIbuM+yf5lY4we4k2J0Eu5NgdzpMWqMKpl1XZ7D6\nOQ4rsQvYXewApjsYp2Olk+F7pbkVTrA7CXYnwe4k2J0Ok5Z+7eYpdgirz1e6f/A6pnsZ9e2hTkLV\nb0j/nY/fmlvhBLuTYHcS7E6C3el5fNHuLJ3ZcBirfz+4GLuBadfVXkxT2vz+32CPNLfCCXYnwe4k\n2J0Eu/OHQWY8pj3vB7H31WsXYTpfVPvlNV/pNNN5WP2c9+HQ3Aon2J0Eu5NgdxLsTnHS0oOatHZj\n9flKdw3qvIc32B5ssPOVaG6FE+xOgt1JsDsJdqc4aU3BjmP13zjU0zzEdBLWTkyfjOn7wUHMV6K5\nFU6wOwl2J8HuJNid4qSl/VIXqxfrHkB9fqX7EfdjL7Hl2GDnK9HcCifYnQS7k2B3EuxOcdLSSVj1\nOwkvYTrhajv2AtN8Na6Pt/ZvaG6FE+xOgt1JsDsJdqc4aZ2vXrIV068d6iR3fXuo33zWbq//T3Mr\nnGB3EuxOgt1JsDu/AdGxd4w8otT7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=240x240 at 0x7F4DC4FD8438>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = cnn.session.run(feed_forwards(cnn, cnn.input, 1), {cnn.input: image})[0, :, :, 6]\n",
    "f1 = np.repeat(f, 10, 0)\n",
    "f1 = np.repeat(f1, 10, 1)\n",
    "Image.fromarray((255 * (f1 - f1.min()) / (f1.max() - f1.min())).astype('uint8'), mode='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAACWCAAAAAAZai4+AAABBUlEQVR4nO3asUkFURRFUb9MKUZi\nByY2YneWYGJkF7agCIKZmRqaHViRP9grPQxsbji80/3FcjvXh7kec32Z6+Vc/01ZoixRlihLlCXK\nEmWJskRZoixRlihLlCXKEsf1nG/m+jrXL475c6bXKkuUJcoSZYmyRFmiLFGWKEuUJcoSZYmyRFni\n9DPn/cbmfa77X9D+9kyvVZYoS5QlyhJlibJEWaIsUZYoS5QlyhJlibLE8TTnq7l+zPVxrvv1zple\nqyxRlihLlCXKEmWJskRZoixRlihLlCXKEmWJ43POd3N9nuv3XN/meqbXKkuUJcoSZYmyRFmiLFGW\nKEuUJcoSZYmyRFniFxsADzLBFBuDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=150x150 at 0x7F4DC4F572E8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = np.repeat(filters_1[:,:,0,4], 30, 0)\n",
    "f1 = np.repeat(f1, 30, 1)\n",
    "f1 = f1\n",
    "Image.fromarray((255 * (f1 - f1.min()) / (f1.max() - f1.min())).astype('uint8'), mode='L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning to KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "knn = knn.fit(train_in[:5000], train_labels[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051400000000000001"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    np.argmax(knn.predict(train_in[:5000]), axis=1) != \\\n",
    "    np.argmax(train_labels[:5000], axis=1)\n",
    ") / train_in[:5000].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.068000000000000005"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    np.argmax(knn.predict(test_in[:5000]), axis=1) != \\\n",
    "    np.argmax(test_labels[:5000], axis=1)\n",
    ") / test_labels[:5000].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train = train_in[:5000].reshape((5000, 28, 28, 1))\n",
    "raw_test = test_in[:5000].reshape((5000, 28, 28, 1))\n",
    "\n",
    "mapped_train = cnn.session.run(feed_forwards(cnn, cnn.input, 1), {cnn.input: raw_train})\n",
    "mapped_train = mapped_train.reshape((5000, 4608))\n",
    "mapped_test = cnn.session.run(feed_forwards(cnn, cnn.input, 1), {cnn.input: raw_test})\n",
    "mapped_test = mapped_test.reshape((5000, 4608))\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "knn = knn.fit(mapped_train, train_labels[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040599999999999997"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    np.argmax(knn.predict(mapped_train), axis=1) != \\\n",
    "    np.argmax(train_labels[:5000], axis=1)\n",
    ") / mapped_image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060600000000000001"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    np.argmax(knn.predict(mapped_test), axis=1) != \\\n",
    "    np.argmax(test_labels[:5000], axis=1)\n",
    ") / mapped_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train = train_in[:5000].reshape((5000, 28, 28, 1))\n",
    "raw_test = test_in[:5000].reshape((5000, 28, 28, 1))\n",
    "\n",
    "mapped_train = cnn.session.run(feed_forwards(cnn, cnn.input, 3), {cnn.input: raw_train})\n",
    "mapped_train = mapped_train.reshape((5000, 72))\n",
    "mapped_test = cnn.session.run(feed_forwards(cnn, cnn.input, 3), {cnn.input: raw_test})\n",
    "mapped_test = mapped_test.reshape((5000, 72))\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "knn = knn.fit(mapped_train, train_labels[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    np.argmax(knn.predict(mapped_train), axis=1) != \\\n",
    "    np.argmax(train_labels[:5000], axis=1)\n",
    ") / mapped_image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023800000000000002"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    np.argmax(knn.predict(mapped_test), axis=1) != \\\n",
    "    np.argmax(test_labels[:5000], axis=1)\n",
    ") / mapped_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Transfer Learning to SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "svm = LinearSVC()\n",
    "svm = svm.fit(train_in[:5000], np.argmax(train_labels[:5000], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0083999999999999995"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    svm.predict(train_in[:5000]) != \\\n",
    "    np.argmax(train_labels[:5000], axis=1)\n",
    ") / train_in[:5000].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1152"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    svm.predict(test_in[:5000]) != \\\n",
    "    np.argmax(test_labels[:5000], axis=1)\n",
    ") / test_labels[:5000].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1-Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_train = train_in[:5000].reshape((5000, 28, 28, 1))\n",
    "raw_test = test_in[:5000].reshape((5000, 28, 28, 1))\n",
    "\n",
    "mapped_train = cnn.session.run(feed_forwards(cnn, cnn.input, 1), {cnn.input: raw_train})\n",
    "mapped_train = mapped_train.reshape((5000, 4608))\n",
    "mapped_test = cnn.session.run(feed_forwards(cnn, cnn.input, 1), {cnn.input: raw_test})\n",
    "mapped_test = mapped_test.reshape((5000, 4608))\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm = svm.fit(mapped_train, np.argmax(train_labels[:5000], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    svm.predict(mapped_train) != \\\n",
    "    np.argmax(train_labels[:5000], axis=1)\n",
    ") / mapped_image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032599999999999997"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    svm.predict(mapped_test) != \\\n",
    "    np.argmax(test_labels[:5000], axis=1)\n",
    ") / mapped_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3-Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_train = train_in[:5000].reshape((5000, 28, 28, 1))\n",
    "raw_test = test_in[:5000].reshape((5000, 28, 28, 1))\n",
    "\n",
    "mapped_train = cnn.session.run(feed_forwards(cnn, cnn.input, 3), {cnn.input: raw_train})\n",
    "mapped_train = mapped_train.reshape((5000, 72))\n",
    "mapped_test = cnn.session.run(feed_forwards(cnn, cnn.input, 3), {cnn.input: raw_test})\n",
    "mapped_test = mapped_test.reshape((5000, 72))\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm = svm.fit(mapped_train, np.argmax(train_labels[:5000], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    svm.predict(mapped_train) != \\\n",
    "    np.argmax(train_labels[:5000], axis=1)\n",
    ") / mapped_image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023199999999999998"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(\n",
    "    svm.predict(mapped_test) != \\\n",
    "    np.argmax(test_labels[:5000], axis=1)\n",
    ") / mapped_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
